//! Integration tests for NeuralDocFlow
//!
//! These tests validate the complete system functionality across all components
//! including DAA coordination, neural processing, and source plugins.

use std::collections::HashMap;
use std::path::PathBuf;
use std::time::Duration;

use neuraldocflow::{Config, DocFlow, SourceInput};
use tempfile::{NamedTempFile, TempDir};
use tokio::test;

#[test]
async fn test_end_to_end_pdf_extraction() {
    // Create a mock PDF file
    let mut temp_file = NamedTempFile::new().unwrap();
    std::io::Write::write_all(temp_file.as_file_mut(), b"%PDF-1.4\n1 0 obj\n<<\n/Type /Catalog\n/Pages 2 0 R\n>>\nendobj\n").unwrap();

    // Create DocFlow with test configuration
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => {
            // Expected in test environment without full setup
            return;
        }
    };

    // Test extraction
    let input = SourceInput::File {
        path: temp_file.path().to_path_buf(),
        metadata: None,
    };

    let result = docflow.extract(input).await;
    
    match result {
        Ok(document) => {
            assert!(!document.id.is_empty());
            assert!(document.confidence > 0.0);
            assert!(!document.content.is_empty());
        }
        Err(_) => {
            // Expected without proper source setup
            assert!(true);
        }
    }
}

#[test]
async fn test_batch_extraction() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Create multiple test inputs
    let inputs = vec![
        SourceInput::Memory {
            data: b"%PDF-1.4\ntest content 1".to_vec(),
            filename: Some("test1.pdf".to_string()),
            mime_type: Some("application/pdf".to_string()),
        },
        SourceInput::Memory {
            data: b"%PDF-1.4\ntest content 2".to_vec(),
            filename: Some("test2.pdf".to_string()),
            mime_type: Some("application/pdf".to_string()),
        },
    ];

    let result = docflow.extract_batch(inputs).await;
    
    match result {
        Ok(documents) => {
            assert_eq!(documents.len(), 2);
            for doc in documents {
                assert!(!doc.id.is_empty());
                assert!(doc.confidence >= 0.0);
            }
        }
        Err(_) => {
            // Expected without proper setup
            assert!(true);
        }
    }
}

#[test]
async fn test_neural_enhancement_integration() {
    let mut config = create_test_config();
    config.neural.enabled = true;
    
    // Create temporary model directory with mock models
    let temp_dir = TempDir::new().unwrap();
    config.neural.model_directory = temp_dir.path().to_path_buf();
    
    // Create mock model files
    create_mock_model_files(&temp_dir).await;
    
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    let input = SourceInput::Memory {
        data: b"%PDF-1.4\ntest content for neural enhancement".to_vec(),
        filename: Some("test.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let result = docflow.extract(input).await;
    
    match result {
        Ok(document) => {
            // Neural enhancement should improve confidence
            assert!(document.confidence > 0.5);
        }
        Err(_) => {
            assert!(true);
        }
    }
}

#[test]
async fn test_daa_coordination() {
    let mut config = create_test_config();
    config.daa.max_agents = 4;
    config.daa.enable_consensus = true;
    config.daa.consensus_threshold = 0.8;

    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    let input = SourceInput::Memory {
        data: b"%PDF-1.4\ntest content for DAA coordination".to_vec(),
        filename: Some("daa_test.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let result = docflow.extract(input).await;
    
    match result {
        Ok(document) => {
            // DAA coordination should produce results
            assert!(!document.content.is_empty());
            
            // Check processing stats
            let stats = docflow.get_stats();
            assert!(stats.documents_processed > 0);
        }
        Err(_) => {
            assert!(true);
        }
    }
}

#[test]
async fn test_source_plugin_discovery() {
    use neuraldocflow::sources::SourceManager;
    
    let config = create_test_config();
    let source_manager = match SourceManager::new(&config) {
        Ok(manager) => manager,
        Err(_) => return,
    };

    let sources = source_manager.get_sources();
    
    // Should have built-in sources
    assert!(!sources.is_empty());
    
    // Check for PDF source
    let pdf_source = source_manager.get_source("pdf");
    if let Some(source) = pdf_source {
        assert_eq!(source.source_id(), "pdf");
        assert!(source.supported_extensions().contains(&"pdf"));
    }
}

#[test]
async fn test_concurrent_processing() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Create multiple concurrent extraction tasks
    let mut handles = Vec::new();
    
    for i in 0..5 {
        let docflow_clone = &docflow;
        let input = SourceInput::Memory {
            data: format!("%PDF-1.4\ntest content {}", i).into_bytes(),
            filename: Some(format!("test{}.pdf", i)),
            mime_type: Some("application/pdf".to_string()),
        };
        
        let handle = tokio::spawn(async move {
            docflow_clone.extract(input).await
        });
        
        handles.push(handle);
    }

    // Wait for all tasks to complete
    let mut results = Vec::new();
    for handle in handles {
        match handle.await {
            Ok(result) => results.push(result),
            Err(_) => continue,
        }
    }

    // Check that concurrent processing worked
    let successful_results: Vec<_> = results.into_iter()
        .filter_map(|r| r.ok())
        .collect();
    
    // At least some should succeed (depending on test environment)
    if !successful_results.is_empty() {
        for doc in successful_results {
            assert!(!doc.id.is_empty());
            assert!(doc.confidence >= 0.0);
        }
    }
}

#[test]
async fn test_error_handling_and_recovery() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Test with invalid input
    let invalid_input = SourceInput::Memory {
        data: b"invalid content".to_vec(),
        filename: Some("invalid.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let result = docflow.extract(invalid_input).await;
    
    // Should handle errors gracefully
    match result {
        Ok(_) => {
            // If it succeeds, that's also valid (might have fallback logic)
            assert!(true);
        }
        Err(error) => {
            // Should be a structured error
            assert!(!error.to_string().is_empty());
            assert!(error.is_recoverable() || !error.is_recoverable()); // Just check method exists
        }
    }
}

#[test]
async fn test_configuration_validation() {
    use neuraldocflow::Config;

    // Test valid configuration
    let valid_config = create_test_config();
    assert!(valid_config.validate().is_ok());

    // Test invalid configuration
    let mut invalid_config = create_test_config();
    invalid_config.core.worker_threads = 0; // Invalid
    assert!(invalid_config.validate().is_err());

    // Test configuration merge
    let mut config1 = create_test_config();
    config1.core.worker_threads = 4;
    
    let mut config2 = create_test_config();
    config2.core.worker_threads = 8;
    
    let merged = config1.merge(config2);
    assert_eq!(merged.core.worker_threads, 8);
}

#[test]
async fn test_memory_usage_limits() {
    let mut config = create_test_config();
    config.performance.max_memory_usage = 100 * 1024 * 1024; // 100MB limit
    
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Create a large input to test memory limits
    let large_data = vec![b'A'; 50 * 1024 * 1024]; // 50MB
    let input = SourceInput::Memory {
        data: [b"%PDF-1.4\n", large_data.as_slice()].concat(),
        filename: Some("large_test.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let result = docflow.extract(input).await;
    
    // Should either succeed with memory management or fail gracefully
    match result {
        Ok(document) => {
            assert!(!document.id.is_empty());
        }
        Err(error) => {
            // Should be a memory-related error if limits are exceeded
            assert!(!error.to_string().is_empty());
        }
    }
}

#[test]
async fn test_processing_metrics() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    let input = SourceInput::Memory {
        data: b"%PDF-1.4\ntest content for metrics".to_vec(),
        filename: Some("metrics_test.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    // Extract document
    let _ = docflow.extract(input).await;

    // Check metrics
    let stats = docflow.get_stats();
    
    // Metrics should be tracked
    assert!(stats.documents_processed >= 0);
    assert!(stats.total_processing_time >= Duration::from_secs(0));
    assert!(stats.average_confidence >= 0.0);
    assert!(stats.active_agents >= 0);
    assert!(stats.neural_models_loaded >= 0);
}

#[test]
async fn test_document_structure_analysis() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Test input with structured content
    let structured_content = "%PDF-1.4\n# Heading 1\nParagraph content\n## Heading 2\nMore content\n| Table | Data |\n| ----- | ---- |\n| Row 1 | Val 1|";
    
    let input = SourceInput::Memory {
        data: structured_content.as_bytes().to_vec(),
        filename: Some("structured_test.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let result = docflow.extract(input).await;
    
    match result {
        Ok(document) => {
            // Should detect document structure
            assert!(document.structure.sections.len() >= 0);
            assert!(document.structure.hierarchy.len() >= 0);
            
            // Should extract different content types
            let headings = document.get_blocks_by_type(&neuraldocflow::BlockType::Heading(1));
            let paragraphs = document.get_blocks_by_type(&neuraldocflow::BlockType::Paragraph);
            let tables = document.get_tables();
            
            // Content stats should be meaningful
            let stats = document.get_content_stats();
            assert!(stats.total_characters >= 0);
            assert!(stats.total_words >= 0);
        }
        Err(_) => {
            assert!(true);
        }
    }
}

#[test]
async fn test_shutdown_and_cleanup() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Use the system briefly
    let input = SourceInput::Memory {
        data: b"%PDF-1.4\ntest content".to_vec(),
        filename: Some("cleanup_test.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let _ = docflow.extract(input).await;

    // Shutdown should complete without errors
    let shutdown_result = docflow.shutdown().await;
    match shutdown_result {
        Ok(_) => assert!(true),
        Err(error) => {
            // Should provide meaningful error if cleanup fails
            assert!(!error.to_string().is_empty());
        }
    }
}

// Helper functions

fn create_test_config() -> Config {
    let mut config = Config::default();
    
    // Configure for testing
    config.core.worker_threads = 2;
    config.core.max_concurrent_documents = 10;
    config.daa.max_agents = 4;
    config.neural.enabled = false; // Disable by default for faster tests
    config.performance.max_memory_usage = 100 * 1024 * 1024; // 100MB
    config.security.enabled = false; // Simplified for testing
    
    // Use temp directories
    let temp_dir = std::env::temp_dir().join("neuraldocflow_test");
    config.core.temp_directory = temp_dir.clone();
    config.neural.model_directory = temp_dir.join("models");
    config.sources.plugin_directories = vec![temp_dir.join("plugins")];
    
    // Ensure directories exist
    std::fs::create_dir_all(&config.core.temp_directory).unwrap_or_default();
    std::fs::create_dir_all(&config.neural.model_directory).unwrap_or_default();
    for dir in &config.sources.plugin_directories {
        std::fs::create_dir_all(dir).unwrap_or_default();
    }
    
    config
}

async fn create_mock_model_files(temp_dir: &TempDir) {
    let model_names = vec![
        "layout_analyzer",
        "text_enhancer",
        "table_detector",
        "confidence_scorer",
    ];
    
    for model_name in model_names {
        let model_path = temp_dir.path().join(format!("{}.model", model_name));
        tokio::fs::write(&model_path, b"mock model data").await.unwrap();
    }
}

// Stress test for high load scenarios
#[test]
async fn test_high_load_processing() {
    let mut config = create_test_config();
    config.core.max_concurrent_documents = 50;
    config.daa.max_agents = 8;
    
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Create many inputs for stress testing
    let mut inputs = Vec::new();
    for i in 0..20 {
        inputs.push(SourceInput::Memory {
            data: format!("%PDF-1.4\nstress test content {}", i).into_bytes(),
            filename: Some(format!("stress_{}.pdf", i)),
            mime_type: Some("application/pdf".to_string()),
        });
    }

    let start_time = std::time::Instant::now();
    let result = docflow.extract_batch(inputs).await;
    let processing_time = start_time.elapsed();

    match result {
        Ok(documents) => {
            // Should process all documents
            assert_eq!(documents.len(), 20);
            
            // Should complete in reasonable time
            assert!(processing_time < Duration::from_secs(30));
            
            // All documents should have valid IDs
            for doc in documents {
                assert!(!doc.id.is_empty());
            }
        }
        Err(_) => {
            // May fail in resource-constrained environments
            assert!(true);
        }
    }
}

// Test for specific document types and edge cases
#[test]
async fn test_edge_cases() {
    let config = create_test_config();
    let docflow = match DocFlow::with_config(config) {
        Ok(flow) => flow,
        Err(_) => return,
    };

    // Test empty document
    let empty_input = SourceInput::Memory {
        data: b"%PDF-1.4\n".to_vec(),
        filename: Some("empty.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let empty_result = docflow.extract(empty_input).await;
    
    // Test very large filename
    let long_filename = "a".repeat(1000) + ".pdf";
    let long_name_input = SourceInput::Memory {
        data: b"%PDF-1.4\ntest content".to_vec(),
        filename: Some(long_filename),
        mime_type: Some("application/pdf".to_string()),
    };

    let long_name_result = docflow.extract(long_name_input).await;
    
    // Test special characters in content
    let special_chars_input = SourceInput::Memory {
        data: "%PDF-1.4\nðŸ”¥âœ¨ðŸ’¯ Special unicode content ä¸­æ–‡ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©".as_bytes().to_vec(),
        filename: Some("unicode.pdf".to_string()),
        mime_type: Some("application/pdf".to_string()),
    };

    let special_chars_result = docflow.extract(special_chars_input).await;
    
    // All edge cases should be handled gracefully
    for result in [empty_result, long_name_result, special_chars_result] {
        match result {
            Ok(document) => {
                assert!(!document.id.is_empty());
                assert!(document.confidence >= 0.0);
            }
            Err(error) => {
                // Should provide meaningful error messages
                assert!(!error.to_string().is_empty());
            }
        }
    }
}