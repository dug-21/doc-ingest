//! High-accuracy malware detection neural model (>99.5% accuracy target)

use crate::models::base::{BaseNeuralModel, ModelConfig, ModelMetrics, NeuralSecurityModel, TrainingData, TrainingResult, ValidationResult};
use neural_doc_flow_core::ProcessingError;
use std::path::{Path, PathBuf};

/// Neural model for malware detection
/// Targets >99.5% accuracy on malware classification
pub struct MalwareDetectorModel {
    base_model: BaseNeuralModel,
    model_path: PathBuf,
}

impl MalwareDetectorModel {
    /// Create a new malware detector model
    pub fn new() -> Result<Self, ProcessingError> {
        let config = ModelConfig {
            name: "MalwareDetector".to_string(),
            version: "1.0.0".to_string(),
            input_size: 256,  // Extended feature set for high accuracy
            output_size: 1,   // Binary classification (malware/benign)
            hidden_layers: vec![512, 256, 128, 64], // Deep architecture for complex patterns
            activation_function: "tanh".to_string(),
            learning_rate: 0.001,
            momentum: 0.95,
            target_error: 0.0001, // Very low error for high accuracy
            max_epochs: 50000,
            simd_enabled: true,
        };
        
        let base_model = BaseNeuralModel::new(config)?;
        
        Ok(Self {
            base_model,
            model_path: PathBuf::from("models/malware_detector.fann"),
        })
    }
    
    /// Load or create model
    pub fn load_or_create(model_dir: &Path) -> Result<Self, ProcessingError> {
        let mut model = Self::new()?;
        let model_path = model_dir.join("malware_detector.fann");
        model.model_path = model_path.clone();
        
        if model_path.exists() {
            model.load(&model_path)?;
        }
        
        Ok(model)
    }
    
    /// Extract extended feature set for malware detection
    pub fn extract_features(raw_features: &crate::SecurityFeatures) -> Vec<f32> {
        let mut features = Vec::with_capacity(256);
        
        // Basic features (normalized)
        features.push((raw_features.file_size as f32).ln() / 20.0); // Log-normalized size
        features.push(raw_features.header_entropy / 8.0);
        features.push((raw_features.stream_count as f32) / 50.0);
        features.push(if raw_features.javascript_present { 1.0 } else { 0.0 });
        features.push((raw_features.embedded_files.len() as f32) / 20.0);
        features.push((raw_features.suspicious_keywords.len() as f32) / 30.0);
        features.push((raw_features.url_count as f32) / 50.0);
        features.push(raw_features.obfuscation_score);
        
        // Statistical features
        let keyword_density = raw_features.suspicious_keywords.len() as f32 / 
            (raw_features.file_size as f32 / 1000.0).max(1.0);
        features.push(keyword_density.min(1.0));
        
        // Entropy variations
        features.push((raw_features.header_entropy - 5.0).abs() / 3.0); // Deviation from normal
        
        // File type indicators (one-hot encoding for common malware carriers)
        let file_types = ["exe", "dll", "scr", "bat", "cmd", "ps1", "vbs", "js"];
        for ft in &file_types {
            let has_type = raw_features.embedded_files.iter()
                .any(|f| f.file_type.to_lowercase().contains(ft));
            features.push(if has_type { 1.0 } else { 0.0 });
        }
        
        // Behavioral indicators
        features.push((raw_features.embedded_files.iter()
            .filter(|f| f.size > 1_000_000).count() as f32) / 10.0); // Large embedded files
        
        // Pattern-based features
        let suspicious_patterns = [
            "eval", "exec", "system", "shell", "powershell", "cmd.exe",
            "subprocess", "os.system", "Runtime.exec", "WScript.Shell",
            "ActiveXObject", "document.write", "innerHTML", "outerHTML",
            "iframe", "object", "embed", "applet", "form", "action"
        ];
        
        for pattern in &suspicious_patterns {
            let count = raw_features.suspicious_keywords.iter()
                .filter(|k| k.contains(pattern)).count();
            features.push((count as f32).min(1.0));
        }
        
        // Advanced obfuscation indicators
        features.push(if raw_features.obfuscation_score > 0.7 { 1.0 } else { 0.0 });
        features.push(if raw_features.header_entropy > 7.5 { 1.0 } else { 0.0 });
        
        // Size anomaly indicators
        features.push(if raw_features.file_size < 1000 { 1.0 } else { 0.0 }); // Too small
        features.push(if raw_features.file_size > 100_000_000 { 1.0 } else { 0.0 }); // Too large
        
        // Pad to expected size
        while features.len() < 256 {
            features.push(0.0);
        }
        
        features
    }
    
    /// Predict malware probability
    pub fn predict(&self, features: &[f32]) -> Result<f32, ProcessingError> {
        let output = self.base_model.network.lock().unwrap().run(features);
        Ok(output[0])
    }
    
    /// Get detection result with confidence
    pub fn detect(&self, features: &[f32]) -> Result<MalwareDetectionResult, ProcessingError> {
        let probability = self.predict(features)?;
        
        // High confidence thresholds for 99.5% accuracy
        let (is_malware, confidence) = if probability > 0.95 {
            (true, 0.99)
        } else if probability > 0.8 {
            (true, 0.85)
        } else if probability < 0.05 {
            (false, 0.99)
        } else if probability < 0.2 {
            (false, 0.85)
        } else {
            (probability > 0.5, 0.6)
        };
        
        Ok(MalwareDetectionResult {
            probability,
            is_malware,
            confidence,
            threat_level: self.calculate_threat_level(probability),
        })
    }
    
    fn calculate_threat_level(&self, probability: f32) -> ThreatLevel {
        match probability {
            p if p > 0.9 => ThreatLevel::Critical,
            p if p > 0.7 => ThreatLevel::High,
            p if p > 0.5 => ThreatLevel::Medium,
            p if p > 0.3 => ThreatLevel::Low,
            _ => ThreatLevel::Safe,
        }
    }
}

impl NeuralSecurityModel for MalwareDetectorModel {
    fn name(&self) -> &str {
        &self.base_model.config.name
    }
    
    fn version(&self) -> &str {
        &self.base_model.config.version
    }
    
    fn input_size(&self) -> usize {
        self.base_model.config.input_size
    }
    
    fn output_size(&self) -> usize {
        self.base_model.config.output_size
    }
    
    fn predict(&self, features: &[f32]) -> Result<Vec<f32>, ProcessingError> {
        Ok(self.base_model.network.lock().unwrap().run(features))
    }
    
    fn train(&mut self, data: &TrainingData) -> Result<TrainingResult, ProcessingError> {
        // Apply class balancing for high accuracy
        let balanced_data = self.balance_training_data(data);
        self.base_model.train_network(&balanced_data)
    }
    
    fn save(&self, path: &Path) -> Result<(), ProcessingError> {
        self.base_model.save_network(path)
    }
    
    fn load(&mut self, path: &Path) -> Result<(), ProcessingError> {
        self.base_model.load_network(path)
    }
    
    fn get_metrics(&self) -> ModelMetrics {
        self.base_model.metrics.lock().unwrap().clone()
    }
    
    fn validate(&self, test_data: &TrainingData) -> Result<ValidationResult, ProcessingError> {
        self.base_model.validate_network(test_data)
    }
}

impl MalwareDetectorModel {
    /// Balance training data to handle class imbalance
    fn balance_training_data(&self, data: &TrainingData) -> TrainingData {
        // Count positive and negative samples
        let mut positive_samples = Vec::new();
        let mut negative_samples = Vec::new();
        
        for (i, output) in data.outputs.iter().enumerate() {
            if output[0] > 0.5 {
                positive_samples.push(i);
            } else {
                negative_samples.push(i);
            }
        }
        
        // Balance by oversampling minority class
        let target_size = positive_samples.len().max(negative_samples.len());
        let mut balanced_inputs = Vec::new();
        let mut balanced_outputs = Vec::new();
        
        // Add all samples
        for i in 0..data.inputs.len() {
            balanced_inputs.push(data.inputs[i].clone());
            balanced_outputs.push(data.outputs[i].clone());
        }
        
        // Oversample minority class
        if positive_samples.len() < target_size {
            let deficit = target_size - positive_samples.len();
            for i in 0..deficit {
                let idx = positive_samples[i % positive_samples.len()];
                balanced_inputs.push(data.inputs[idx].clone());
                balanced_outputs.push(data.outputs[idx].clone());
            }
        } else if negative_samples.len() < target_size {
            let deficit = target_size - negative_samples.len();
            for i in 0..deficit {
                let idx = negative_samples[i % negative_samples.len()];
                balanced_inputs.push(data.inputs[idx].clone());
                balanced_outputs.push(data.outputs[idx].clone());
            }
        }
        
        TrainingData::new(balanced_inputs, balanced_outputs)
    }
}

/// Malware detection result
#[derive(Debug, Clone)]
pub struct MalwareDetectionResult {
    pub probability: f32,
    pub is_malware: bool,
    pub confidence: f32,
    pub threat_level: ThreatLevel,
}

/// Threat level enumeration
#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum ThreatLevel {
    Safe,
    Low,
    Medium,
    High,
    Critical,
}